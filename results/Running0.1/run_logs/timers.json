{
    "name": "root",
    "gauges": {
        "Walker.Policy.Entropy.mean": {
            "value": 1.3187984228134155,
            "min": 1.2790400981903076,
            "max": 1.3187984228134155,
            "count": 43
        },
        "Walker.Policy.Entropy.sum": {
            "value": 38382.30859375,
            "min": 9485.361328125,
            "max": 40249.5625,
            "count": 43
        },
        "Walker.Environment.EpisodeLength.mean": {
            "value": 266.17857142857144,
            "min": 251.6386554621849,
            "max": 292.8181818181818,
            "count": 43
        },
        "Walker.Environment.EpisodeLength.sum": {
            "value": 29812.0,
            "min": 6442.0,
            "max": 30109.0,
            "count": 43
        },
        "Walker.Step.mean": {
            "value": 6089762.0,
            "min": 4829814.0,
            "max": 6089762.0,
            "count": 43
        },
        "Walker.Step.sum": {
            "value": 6089762.0,
            "min": 4829814.0,
            "max": 6089762.0,
            "count": 43
        },
        "Walker.Policy.ExtrinsicValueEstimate.mean": {
            "value": 23.084787368774414,
            "min": 19.494367599487305,
            "max": 23.084787368774414,
            "count": 43
        },
        "Walker.Policy.ExtrinsicValueEstimate.sum": {
            "value": 2585.49609375,
            "min": 411.0618896484375,
            "max": 2645.094970703125,
            "count": 43
        },
        "Walker.Environment.CumulativeReward.mean": {
            "value": 61.653022221156526,
            "min": 52.06244356632233,
            "max": 61.653022221156526,
            "count": 43
        },
        "Walker.Environment.CumulativeReward.sum": {
            "value": 6905.138488769531,
            "min": 1158.6067028045654,
            "max": 6933.86148172617,
            "count": 43
        },
        "Walker.Policy.ExtrinsicReward.mean": {
            "value": 61.653022221156526,
            "min": 52.06244356632233,
            "max": 61.653022221156526,
            "count": 43
        },
        "Walker.Policy.ExtrinsicReward.sum": {
            "value": 6905.138488769531,
            "min": 1158.6067028045654,
            "max": 6933.86148172617,
            "count": 43
        },
        "Walker.IsTraining.mean": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 43
        },
        "Walker.IsTraining.sum": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 43
        },
        "Walker.Losses.PolicyLoss.mean": {
            "value": 0.015508905469808574,
            "min": 0.011612258037591043,
            "max": 0.02265836865796397,
            "count": 42
        },
        "Walker.Losses.PolicyLoss.sum": {
            "value": 0.031017810939617148,
            "min": 0.011612258037591043,
            "max": 0.04099525046452375,
            "count": 42
        },
        "Walker.Losses.ValueLoss.mean": {
            "value": 2.1374456882476807,
            "min": 0.7482226669788361,
            "max": 3.8725728193918862,
            "count": 42
        },
        "Walker.Losses.ValueLoss.sum": {
            "value": 4.274891376495361,
            "min": 0.7482226669788361,
            "max": 7.7451456387837725,
            "count": 42
        },
        "Walker.Policy.LearningRate.mean": {
            "value": 0.0002392852452382583,
            "min": 0.0002392852452382583,
            "max": 0.0002515564761478467,
            "count": 42
        },
        "Walker.Policy.LearningRate.sum": {
            "value": 0.0004785704904765166,
            "min": 0.00023959538013487998,
            "max": 0.0005024964125012066,
            "count": 42
        },
        "Walker.Policy.Epsilon.mean": {
            "value": 0.1797617416666667,
            "min": 0.1797617416666667,
            "max": 0.18385215333333338,
            "count": 42
        },
        "Walker.Policy.Epsilon.sum": {
            "value": 0.3595234833333334,
            "min": 0.17986511999999996,
            "max": 0.3674987933333334,
            "count": 42
        },
        "Walker.Policy.Beta.mean": {
            "value": 0.003990110909166667,
            "min": 0.003990110909166667,
            "max": 0.004194222451333333,
            "count": 42
        },
        "Walker.Policy.Beta.sum": {
            "value": 0.007980221818333334,
            "min": 0.003995269487999999,
            "max": 0.008378189787333333,
            "count": 42
        }
    },
    "metadata": {
        "timer_format_version": "0.1.0",
        "start_time_seconds": "1685742641",
        "python_version": "3.9.13 (tags/v3.9.13:6de2ca5, May 17 2022, 16:36:42) [MSC v.1929 64 bit (AMD64)]",
        "command_line_arguments": "C:\\Users\\asaju\\Desktop\\MLAgents\\ml-agents\\venv\\Scripts\\mlagents-learn config/ppo/Walker.yaml --run-id=Running0.1 --resume",
        "mlagents_version": "0.30.0",
        "mlagents_envs_version": "0.30.0",
        "communication_protocol_version": "1.5.0",
        "pytorch_version": "2.0.1+cu117",
        "numpy_version": "1.21.2",
        "end_time_seconds": "1685745137"
    },
    "total": 2496.8880551,
    "count": 1,
    "self": 0.0032157000000552216,
    "children": {
        "run_training.setup": {
            "total": 0.06599080000000002,
            "count": 1,
            "self": 0.06599080000000002
        },
        "TrainerController.start_learning": {
            "total": 2496.8188486000004,
            "count": 1,
            "self": 2.3722311000506124,
            "children": {
                "TrainerController._reset_env": {
                    "total": 15.8502423,
                    "count": 1,
                    "self": 15.8502423
                },
                "TrainerController.advance": {
                    "total": 2478.4510390999494,
                    "count": 165627,
                    "self": 2.5377954999139547,
                    "children": {
                        "env_step": {
                            "total": 2272.392100500044,
                            "count": 165627,
                            "self": 1881.8235579000518,
                            "children": {
                                "SubprocessEnvManager._take_step": {
                                    "total": 388.96465039994433,
                                    "count": 165627,
                                    "self": 8.23369749994066,
                                    "children": {
                                        "TorchPolicy.evaluate": {
                                            "total": 380.7309529000037,
                                            "count": 161887,
                                            "self": 380.7309529000037
                                        }
                                    }
                                },
                                "workers": {
                                    "total": 1.6038922000477847,
                                    "count": 165626,
                                    "self": 0.0,
                                    "children": {
                                        "worker_root": {
                                            "total": 2479.5930655999487,
                                            "count": 165626,
                                            "is_parallel": true,
                                            "self": 727.0484705999122,
                                            "children": {
                                                "steps_from_proto": {
                                                    "total": 0.0003539999999997434,
                                                    "count": 1,
                                                    "is_parallel": true,
                                                    "self": 8.239999999837266e-05,
                                                    "children": {
                                                        "_process_rank_one_or_two_observation": {
                                                            "total": 0.00027160000000137074,
                                                            "count": 2,
                                                            "is_parallel": true,
                                                            "self": 0.00027160000000137074
                                                        }
                                                    }
                                                },
                                                "UnityEnvironment.step": {
                                                    "total": 1752.5442410000364,
                                                    "count": 165626,
                                                    "is_parallel": true,
                                                    "self": 16.744174500174267,
                                                    "children": {
                                                        "UnityEnvironment._generate_step_input": {
                                                            "total": 24.222246499927437,
                                                            "count": 165626,
                                                            "is_parallel": true,
                                                            "self": 24.222246499927437
                                                        },
                                                        "communicator.exchange": {
                                                            "total": 1670.1260204999476,
                                                            "count": 165626,
                                                            "is_parallel": true,
                                                            "self": 1670.1260204999476
                                                        },
                                                        "steps_from_proto": {
                                                            "total": 41.45179949998713,
                                                            "count": 165626,
                                                            "is_parallel": true,
                                                            "self": 10.124638000009611,
                                                            "children": {
                                                                "_process_rank_one_or_two_observation": {
                                                                    "total": 31.32716149997752,
                                                                    "count": 331252,
                                                                    "is_parallel": true,
                                                                    "self": 31.32716149997752
                                                                }
                                                            }
                                                        }
                                                    }
                                                }
                                            }
                                        }
                                    }
                                }
                            }
                        },
                        "trainer_advance": {
                            "total": 203.5211430999915,
                            "count": 165626,
                            "self": 3.227011300054727,
                            "children": {
                                "process_trajectory": {
                                    "total": 49.411076799936865,
                                    "count": 165626,
                                    "self": 49.00618279993682,
                                    "children": {
                                        "RLTrainer._checkpoint": {
                                            "total": 0.4048940000000414,
                                            "count": 3,
                                            "self": 0.4048940000000414
                                        }
                                    }
                                },
                                "_update_policy": {
                                    "total": 150.8830549999999,
                                    "count": 62,
                                    "self": 110.62294919999161,
                                    "children": {
                                        "TorchPPOOptimizer.update": {
                                            "total": 40.26010580000829,
                                            "count": 1860,
                                            "self": 40.26010580000829
                                        }
                                    }
                                }
                            }
                        }
                    }
                },
                "trainer_threads": {
                    "total": 6.000000212225132e-07,
                    "count": 1,
                    "self": 6.000000212225132e-07
                },
                "TrainerController._save_models": {
                    "total": 0.14533550000032847,
                    "count": 1,
                    "self": 0.05345390000002226,
                    "children": {
                        "RLTrainer._checkpoint": {
                            "total": 0.09188160000030621,
                            "count": 1,
                            "self": 0.09188160000030621
                        }
                    }
                }
            }
        }
    }
}